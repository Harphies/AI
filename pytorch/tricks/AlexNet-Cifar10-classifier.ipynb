{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increase the Batch size Instead of reducing the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.determinitic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model settings\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# OTHERS\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "\n",
    "train_indices = torch.arange(0, 48000)\n",
    "valid_indices = torch.arange(48000, 50000)\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize((70,70)),\n",
    "                                    transforms.RandomCrop((64, 64)),\n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((70,70)),\n",
    "                                   transforms.CenterCrop((64,64)),\n",
    "                                   transforms.ToTensor()])\n",
    "\n",
    "train_and_valid = datasets.CIFAR10(root='data',\n",
    "                              train=True,\n",
    "                              transform= train_transform,\n",
    "                              download=True)\n",
    "\n",
    "\n",
    "train_dataset = Subset(train_and_valid, train_indices)\n",
    "valid_dataset = Subset(train_and_valid, valid_indices)\n",
    "test_dataset = datasets.CIFAR10(root='data',\n",
    "                               train= False,\n",
    "                               transform = test_transform,\n",
    "                               download = False)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=4,\n",
    "                         shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=4,\n",
    "                         shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        num_workers=4,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "\n",
      "Image Batch dimension: torch.Size([256, 3, 64, 64])\n",
      "Image label dimension: torch.Size([256])\n",
      "\n",
      "Validation Set:\n",
      "Image batch dimension torch.Size([256, 3, 64, 64])\n",
      "Image batch dimension torch.Size([256])\n",
      "\n",
      " Testing Set\n",
      "Image batch dimension torch.Size([256, 3, 64, 64])\n",
      "labels batch dimension torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# checking the dataset\n",
    "print('Training set:\\n')\n",
    "for images, labels in train_loader:\n",
    "    print('Image Batch dimension:',images.size())\n",
    "    print('Image label dimension:',labels.size())\n",
    "    break\n",
    "# checking the dataset\n",
    "print('\\nValidation Set:')\n",
    "for images, labels in valid_loader:\n",
    "    print('Image batch dimension',images.size())\n",
    "    print('Image batch dimension', labels.size())\n",
    "    break\n",
    "\n",
    "# checking the dataset\n",
    "print('\\n Testing Set')\n",
    "for images,labels in test_loader:\n",
    "    print('Image batch dimension',images.size())\n",
    "    print('labels batch dimension',labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class AlexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6,6))\n",
    "        self.classifier= nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256*6*6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096,num_classes)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 256*6*6)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits,probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy and loss metrics\n",
    "\n",
    "def compute_acc(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    model.eval()\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "        \n",
    "        features = features.to(device)\n",
    "        targets = target.to(device)\n",
    "        \n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas,1)\n",
    "        num_examples +=targets.size(0)\n",
    "        assert predicted_labels.size() == targets.size()\n",
    "        correct_pred+= (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 1\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = AlexNet(NUM_CLASSES)\n",
    "# model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/040 | Batch 000/188 |cost: 2.3013\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-56cffe0e7288>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# save memory during inference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-5891eda8b48a>\u001b[0m in \u001b[0;36mcompute_acc\u001b[1;34m(model, data_loader, device)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dev\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    190\u001b[0m             raise RuntimeError(\n\u001b[0;32m    191\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dev\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[1;32mfrom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[1;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cost_list = []\n",
    "train_acc_list , valid_acc_list = [],[]\n",
    "\n",
    "for epoch  in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features,targets) in enumerate(train_loader):\n",
    "        \n",
    "        # features = features.to(DEVICE)\n",
    "        # targets = targets.to(DEVICE)\n",
    "        \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward() # compute the back prop here:\n",
    "        \n",
    "        # for logging beyond this point\n",
    "        \n",
    "        if not batch_idx % 150:\n",
    "            print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                 f'Batch {batch_idx:03d}/{len(train_loader):03d} |'\n",
    "                 f'cost: {cost:.4f}')\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.set_grad_enabled(False): # save memory during inference\n",
    "            \n",
    "            train_acc = compute_acc(model, train_loader, device=DEVICE)\n",
    "            valid_acc = compute_acc(model, valid_loader, device=DEVICE)\n",
    "            \n",
    "            print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d}\\n'\n",
    "                 f'Train Acc: {train_acc:.2f} | Validation Acc: {valid_acc:.2f}')\n",
    "            train_acc_list.append(train_acc)\n",
    "            valid_acc_list.append(valid_acc)\n",
    "            \n",
    "        elapsed = (time.time() - start_time)/60\n",
    "        print(f'Time Elapsed: {elapsed:.2f} min')\n",
    "        \n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "v cannot be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a593ed66e164>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Minibatch cost'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m plt.plot(np.convolve(cost_list,\n\u001b[1;32m----> 4\u001b[1;33m                     np.ones(200,)/200, mode='valid'),\n\u001b[0m\u001b[0;32m      5\u001b[0m         label = 'Running Average')\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconvolve\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dev\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mconvolve\u001b[1;34m(a, v, mode)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a cannot be empty'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'v cannot be empty'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m     \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mode_from_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrelate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: v cannot be empty"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "plt.plot(cost_list, label='Minibatch cost')\n",
    "plt.plot(np.convolve(cost_list,\n",
    "                    np.ones(200,)/200, mode='valid'),\n",
    "        label = 'Running Average')\n",
    "\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
