{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increase the Batch size Instead of reducing the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.determinitic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model settings\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# OTHERS\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "\n",
    "train_indices = torch.arange(0, 48000)\n",
    "valid_indices = torch.arange(48000, 50000)\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize((70,70)),\n",
    "                                    transforms.RandomCrop((64, 64)),\n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((70,70)),\n",
    "                                   transforms.CenterCrop((64,64)),\n",
    "                                   transforms.ToTensor()])\n",
    "\n",
    "train_and_valid = datasets.CIFAR10(root='data',\n",
    "                              train=True,\n",
    "                              transform= train_transform,\n",
    "                              download=True)\n",
    "\n",
    "\n",
    "train_dataset = Subset(train_and_valid, train_indices)\n",
    "valid_dataset = Subset(train_and_valid, valid_indices)\n",
    "test_dataset = datasets.CIFAR10(root='data',\n",
    "                               train= False,\n",
    "                               transform = test_transform,\n",
    "                               download = False)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=4,\n",
    "                         shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=4,\n",
    "                         shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        num_workers=4,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "\n",
      "Image Batch dimension: torch.Size([256, 3, 64, 64])\n",
      "Image label dimension: torch.Size([256])\n",
      "\n",
      "Validation Set:\n",
      "Image batch dimension torch.Size([256, 3, 64, 64])\n",
      "Image batch dimension torch.Size([256])\n",
      "\n",
      " Testing Set\n",
      "Image batch dimension torch.Size([256, 3, 64, 64])\n",
      "labels batch dimension torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# checking the dataset\n",
    "print('Training set:\\n')\n",
    "for images, labels in train_loader:\n",
    "    print('Image Batch dimension:',images.size())\n",
    "    print('Image label dimension:',labels.size())\n",
    "    break\n",
    "# checking the dataset\n",
    "print('\\nValidation Set:')\n",
    "for images, labels in valid_loader:\n",
    "    print('Image batch dimension',images.size())\n",
    "    print('Image batch dimension', labels.size())\n",
    "    break\n",
    "\n",
    "# checking the dataset\n",
    "print('\\n Testing Set')\n",
    "for images,labels in test_loader:\n",
    "    print('Image batch dimension',images.size())\n",
    "    print('labels batch dimension',labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class AlexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6,6))\n",
    "        self.classifier= nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256*6*6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096,num_classes)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 256*6*6)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits,probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy and loss metrics\n",
    "\n",
    "def compute_acc(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    model.eval()\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "        \n",
    "        features = features.to(device)\n",
    "        targets = target.to(device)\n",
    "        \n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas,1)\n",
    "        num_examples +=targets.size(0)\n",
    "        assert predicted_labels.size() == targets.size()\n",
    "        correct_pred+= (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 1\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = AlexNet(NUM_CLASSES)\n",
    "# model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cost_list = []\n",
    "train_acc_list , valid_acc_list = [],[]\n",
    "\n",
    "for epoch  in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features,targets) in enumerate(train_loader):\n",
    "        \n",
    "        # features = features.to(DEVICE)\n",
    "        # targets = targets.to(DEVICE)\n",
    "        \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward() # compute the back prop here:\n",
    "        \n",
    "        # for logging beyond this point\n",
    "        \n",
    "        if not batch_idx % 150:\n",
    "            print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                 f'Batch {batch_idx:03d}/{len(train_loader):03d} |'\n",
    "                 f'cost: {cost:.4f}')\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.set_grad_enabled(False): # save memory during inference\n",
    "            \n",
    "            train_acc = compute_acc(model, train_loader, device=DEVICE)\n",
    "            valid_acc = compute_acc(model, valid_loader, device=DEVICE)\n",
    "            \n",
    "            print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d}\\n'\n",
    "                 f'Train Acc: {train_acc:.2f} | Validation Acc: {valid_acc:.2f}')\n",
    "            train_acc_list.append(train_acc)\n",
    "            valid_acc_list.append(valid_acc)\n",
    "            \n",
    "        elapsed = (time.time() - start_time)/60\n",
    "        print(f'Time Elapsed: {elapsed:.2f} min')\n",
    "        \n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
