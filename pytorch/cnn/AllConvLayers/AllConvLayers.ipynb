{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project: A convolutional Neural Networks with all layers purely convolution layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages selection\n",
    "- The first things is to import all the neccesary packages needed for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# selct GPU if cuda is available\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings\n",
    "- Configure the device\n",
    "- define all the hyperparameters to be used and needed to be tuned to achive a better accuracy\n",
    "- Load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Batch dimension torch.Size([256, 1, 28, 28])\n",
      "Image Labels dimension torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# hyperparameters\n",
    "random_seed = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 15\n",
    "batch_size = 256\n",
    "\n",
    "# model architecture parameters\n",
    "num_classes = 10\n",
    "\n",
    "# dataset -> MNIST\n",
    "# Note: transforms.ToTensor() scale image from 0-1 range\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data',\n",
    "                              train=True,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data',\n",
    "                             train=False,\n",
    "                             transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)\n",
    "\n",
    "# check the dataset\n",
    "for images, labels in train_loader:\n",
    "    print(\"Image Batch dimension\", images.shape)\n",
    "    print(\"Image Labels dimension\", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the architecture of the model such as\n",
    "- The number of input layers; which is determined by the features of the data\n",
    "- Number of total hidden layers in the model consist of only Convolution layers\n",
    "- The output layer node units is determined by the intended outcome to achieve\n",
    "- Here we have two layers convolutional neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Architecture\n",
    "X -> Conv -> ReLU -> Conv -> ReLU -> Conv -> ReLU -> Conv -> ReLU -> Conv -> ReLU -> Conv -> ReLU -> Conv -> Softmax -> y\n",
    "\"\"\"\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=4,\n",
    "                               kernel_size=(3, 3),\n",
    "                               stride=(1, 1),\n",
    "                               padding=1)\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(in_channels=4,\n",
    "                               out_channels=4,\n",
    "                               kernel_size=(3, 3),\n",
    "                               stride=(2, 2),\n",
    "                               padding=1)\n",
    "        \n",
    "        self.conv_3 = nn.Conv2d(in_channels=4,\n",
    "                               out_channels=8,\n",
    "                               kernel_size=(3, 3),\n",
    "                               stride=(1, 1),\n",
    "                               padding=1)\n",
    "        \n",
    "        self.conv_4 = nn.Conv2d(in_channels=8,\n",
    "                               out_channels=8,\n",
    "                               kernel_size=(3, 3),\n",
    "                               stride=(2, 2),\n",
    "                               padding=1)\n",
    "        \n",
    "        self.conv_5 = nn.Conv2d(in_channels=8,\n",
    "                               out_channels=16,\n",
    "                               kernel_size=(3, 3),\n",
    "                               stride=(1, 1),\n",
    "                               padding=1)\n",
    "        \n",
    "        self.conv_6 = nn.Conv2d(in_channels=16,\n",
    "                               out_channels=16,\n",
    "                               kernel_size=(3, 3),\n",
    "                               stride=(2, 2),\n",
    "                               padding=1)\n",
    "        \n",
    "        self.conv_7 = nn.Conv2d(in_channels=16,\n",
    "                               out_channels=self.num_classes,\n",
    "                               kernel_size=(3, 3),\n",
    "                               stride=(1, 1),\n",
    "                               padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv_1(x)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv_2(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv_3(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv_4(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv_5(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv_6(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv_7(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        logits = F.adaptive_avg_pool2d(out, 1)\n",
    "        # drop the width\n",
    "        logits.squeeze_(-1)\n",
    "        # drop the height\n",
    "        logits.squeeze_(-1)\n",
    "        probas = torch.softmax(logits, dim=1)\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and optimizer\n",
    "- Instantiate the model\n",
    "- define the specific Loss function to be used either cross entropy, MSELoss, etc\n",
    "- define the optimization algorithm to be used either SGD, Adam, RMSprop, Momentum etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "model = ConvNet(num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute accuracy\n",
    "- A function to compute train and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader):\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    for features, labels in data_loader:\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += labels.size(0)\n",
    "        correct_predictions += (predicted_labels == labels).sum()\n",
    "    return correct_predictions.float() / num_examples * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a model requires the following steps\n",
    "- Reset all the gradients to zero (0)\n",
    "- Make a forward pass (make a prediction)\n",
    "- Calculate the loss\n",
    "- Perform back propagation\n",
    "- Update all the parameters (weight and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/015 | Batch: 000/235 | Cost: 2.3051\n",
      "Epoch: 001/015 | Batch: 050/235 | Cost: 2.2912\n",
      "Epoch: 001/015 | Batch: 100/235 | Cost: 2.0543\n",
      "Epoch: 001/015 | Batch: 150/235 | Cost: 1.5351\n",
      "Epoch: 001/015 | Batch: 200/235 | Cost: 1.1741\n",
      "Epoch: 001/015 training accuracy: 74.54%\n",
      "Time Elapsed: 1.12 min\n",
      "Epoch: 002/015 | Batch: 000/235 | Cost: 1.0367\n",
      "Epoch: 002/015 | Batch: 050/235 | Cost: 0.8080\n",
      "Epoch: 002/015 | Batch: 100/235 | Cost: 0.6701\n",
      "Epoch: 002/015 | Batch: 150/235 | Cost: 0.4320\n",
      "Epoch: 002/015 | Batch: 200/235 | Cost: 0.6095\n",
      "Epoch: 002/015 training accuracy: 82.90%\n",
      "Time Elapsed: 2.25 min\n",
      "Epoch: 003/015 | Batch: 000/235 | Cost: 0.5706\n",
      "Epoch: 003/015 | Batch: 050/235 | Cost: 0.4780\n",
      "Epoch: 003/015 | Batch: 100/235 | Cost: 0.5257\n",
      "Epoch: 003/015 | Batch: 150/235 | Cost: 0.5403\n",
      "Epoch: 003/015 | Batch: 200/235 | Cost: 0.6229\n",
      "Epoch: 003/015 training accuracy: 84.66%\n",
      "Time Elapsed: 3.43 min\n",
      "Epoch: 004/015 | Batch: 000/235 | Cost: 0.5428\n",
      "Epoch: 004/015 | Batch: 050/235 | Cost: 0.5109\n",
      "Epoch: 004/015 | Batch: 100/235 | Cost: 0.3519\n",
      "Epoch: 004/015 | Batch: 150/235 | Cost: 0.5110\n",
      "Epoch: 004/015 | Batch: 200/235 | Cost: 0.3432\n",
      "Epoch: 004/015 training accuracy: 86.10%\n",
      "Time Elapsed: 4.57 min\n",
      "Epoch: 005/015 | Batch: 000/235 | Cost: 0.4267\n",
      "Epoch: 005/015 | Batch: 050/235 | Cost: 0.4790\n",
      "Epoch: 005/015 | Batch: 100/235 | Cost: 0.4658\n",
      "Epoch: 005/015 | Batch: 150/235 | Cost: 0.3495\n",
      "Epoch: 005/015 | Batch: 200/235 | Cost: 0.4586\n",
      "Epoch: 005/015 training accuracy: 86.28%\n",
      "Time Elapsed: 5.71 min\n",
      "Epoch: 006/015 | Batch: 000/235 | Cost: 0.4460\n",
      "Epoch: 006/015 | Batch: 050/235 | Cost: 0.3940\n",
      "Epoch: 006/015 | Batch: 100/235 | Cost: 0.4166\n",
      "Epoch: 006/015 | Batch: 150/235 | Cost: 0.3521\n",
      "Epoch: 006/015 | Batch: 200/235 | Cost: 0.2476\n",
      "Epoch: 006/015 training accuracy: 86.91%\n",
      "Time Elapsed: 6.85 min\n",
      "Epoch: 007/015 | Batch: 000/235 | Cost: 0.3507\n",
      "Epoch: 007/015 | Batch: 050/235 | Cost: 0.3500\n",
      "Epoch: 007/015 | Batch: 100/235 | Cost: 0.4825\n",
      "Epoch: 007/015 | Batch: 150/235 | Cost: 0.3522\n",
      "Epoch: 007/015 | Batch: 200/235 | Cost: 0.3374\n",
      "Epoch: 007/015 training accuracy: 87.24%\n",
      "Time Elapsed: 7.99 min\n",
      "Epoch: 008/015 | Batch: 000/235 | Cost: 0.3532\n",
      "Epoch: 008/015 | Batch: 050/235 | Cost: 0.4080\n",
      "Epoch: 008/015 | Batch: 100/235 | Cost: 0.3988\n",
      "Epoch: 008/015 | Batch: 150/235 | Cost: 0.3722\n",
      "Epoch: 008/015 | Batch: 200/235 | Cost: 0.3643\n",
      "Epoch: 008/015 training accuracy: 87.43%\n",
      "Time Elapsed: 9.13 min\n",
      "Epoch: 009/015 | Batch: 000/235 | Cost: 0.3607\n",
      "Epoch: 009/015 | Batch: 050/235 | Cost: 0.3027\n",
      "Epoch: 009/015 | Batch: 100/235 | Cost: 0.2931\n",
      "Epoch: 009/015 | Batch: 150/235 | Cost: 0.4444\n",
      "Epoch: 009/015 | Batch: 200/235 | Cost: 0.3251\n",
      "Epoch: 009/015 training accuracy: 87.20%\n",
      "Time Elapsed: 10.27 min\n",
      "Epoch: 010/015 | Batch: 000/235 | Cost: 0.4710\n",
      "Epoch: 010/015 | Batch: 050/235 | Cost: 0.2800\n",
      "Epoch: 010/015 | Batch: 100/235 | Cost: 0.3961\n",
      "Epoch: 010/015 | Batch: 150/235 | Cost: 0.4199\n",
      "Epoch: 010/015 | Batch: 200/235 | Cost: 0.2863\n",
      "Epoch: 010/015 training accuracy: 87.80%\n",
      "Time Elapsed: 11.41 min\n",
      "Epoch: 011/015 | Batch: 000/235 | Cost: 0.3254\n",
      "Epoch: 011/015 | Batch: 050/235 | Cost: 0.4466\n",
      "Epoch: 011/015 | Batch: 100/235 | Cost: 0.3480\n",
      "Epoch: 011/015 | Batch: 150/235 | Cost: 0.1924\n",
      "Epoch: 011/015 | Batch: 200/235 | Cost: 0.3519\n",
      "Epoch: 011/015 training accuracy: 87.58%\n",
      "Time Elapsed: 12.55 min\n",
      "Epoch: 012/015 | Batch: 000/235 | Cost: 0.4941\n",
      "Epoch: 012/015 | Batch: 050/235 | Cost: 0.2679\n",
      "Epoch: 012/015 | Batch: 100/235 | Cost: 0.3225\n",
      "Epoch: 012/015 | Batch: 150/235 | Cost: 0.3293\n",
      "Epoch: 012/015 | Batch: 200/235 | Cost: 0.3104\n",
      "Epoch: 012/015 training accuracy: 88.06%\n",
      "Time Elapsed: 13.69 min\n",
      "Epoch: 013/015 | Batch: 000/235 | Cost: 0.3037\n",
      "Epoch: 013/015 | Batch: 050/235 | Cost: 0.3955\n",
      "Epoch: 013/015 | Batch: 100/235 | Cost: 0.3412\n",
      "Epoch: 013/015 | Batch: 150/235 | Cost: 0.2814\n",
      "Epoch: 013/015 | Batch: 200/235 | Cost: 0.3060\n",
      "Epoch: 013/015 training accuracy: 88.05%\n",
      "Time Elapsed: 14.82 min\n",
      "Epoch: 014/015 | Batch: 000/235 | Cost: 0.3745\n",
      "Epoch: 014/015 | Batch: 050/235 | Cost: 0.4175\n",
      "Epoch: 014/015 | Batch: 100/235 | Cost: 0.2856\n",
      "Epoch: 014/015 | Batch: 150/235 | Cost: 0.3503\n",
      "Epoch: 014/015 | Batch: 200/235 | Cost: 0.3742\n",
      "Epoch: 014/015 training accuracy: 87.61%\n",
      "Time Elapsed: 15.95 min\n",
      "Epoch: 015/015 | Batch: 000/235 | Cost: 0.3636\n",
      "Epoch: 015/015 | Batch: 050/235 | Cost: 0.3262\n",
      "Epoch: 015/015 | Batch: 100/235 | Cost: 0.2891\n",
      "Epoch: 015/015 | Batch: 150/235 | Cost: 0.2417\n",
      "Epoch: 015/015 | Batch: 200/235 | Cost: 0.2719\n",
      "Epoch: 015/015 training accuracy: 88.19%\n",
      "Time Elapsed: 17.09 min\n",
      "Total Training time: 17.09 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forwward and back prop\n",
    "        output, probas = model(features)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Logging\n",
    "        if not i % 50:\n",
    "            print('Epoch: %03d/%03d | Batch: %03d/%03d | Cost: %.4f'\n",
    "                 %(epoch+1, num_epochs, i, total_step, loss))\n",
    "        \n",
    "    model = model.eval()\n",
    "    print('Epoch: %03d/%03d training accuracy: %.2f%%' %(\n",
    "    epoch+1, num_epochs, compute_accuracy(model, train_loader)))\n",
    "    print('Time Elapsed: %.2f min' %((time.time() - start_time) / 60))\n",
    "print('Total Training time: %.2f min' %((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  88.38%\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy\n",
    "print(\"Test Accuracy:  %.2f%%\" %(compute_accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
