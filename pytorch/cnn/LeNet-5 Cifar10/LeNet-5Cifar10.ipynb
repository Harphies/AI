{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project: LeNet-5 classic network digit classifiers with MNIST datasets\n",
    "Here I redesign the LeNet-5 architecture by replacing the pooling layers with Maxpooling and the hidden layers with relu instead of tanh and the output layers with softmax layers instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages selection\n",
    "- The first things is to import all the neccesary packages needed for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# select GPU if cuda is available\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings\n",
    "- Configure the device\n",
    "- define all the hyperparameters to be used and needed to be tuned to achive a better accuracy\n",
    "- Load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Image batch dimension torch.Size([128, 3, 32, 32])\n",
      "Image label dimension torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# model architecture parameters\n",
    "NUM_FEATURES = 32*32\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# others\n",
    "GRAYSCALE = False\n",
    "\n",
    "# dataset -> CIFAR-10\n",
    "# Note: transforms.ToTensor() scale image from 0-1 range\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='data',\n",
    "                                train=True,\n",
    "                                transform=transforms.ToTensor(),\n",
    "                                download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='data',\n",
    "                               train=False,\n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                         batch_size= BATCH_SIZE,\n",
    "                         shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False)\n",
    "\n",
    "# check the dataset\n",
    "for images, labels in train_loader:\n",
    "    print(\"Image batch dimension\", images.shape)\n",
    "    print(\"Image label dimension\", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the architecture of the model such as\n",
    "- The number of input layers; which is determined by the features of the data\n",
    "- Number of total hidden layers in the model consist of only Convolution layers\n",
    "- The output layer node units is determined by the intended outcome to achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Architecture\n",
    "X -> Conv2d -> ReLU -> MaxPool -> Conv2d -> ReLU -> MaxPool -> Linear -> ReLU -> Linear -> ReLu -> Linear -> Softmax -> y\n",
    "\"\"\"\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, NUM_CLASSES, grayscale=False):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.grayscale = grayscale\n",
    "        self.num_classes = NUM_CLASSES\n",
    "        \n",
    "        if grayscale:\n",
    "            in_channels = 1\n",
    "        else:\n",
    "            in_channels = 3\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(in_channels, 6*in_channels, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(6*in_channels, 16*in_channels, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5*in_channels, 120*in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120*in_channels, 84*in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84*in_channels, self.num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        outputs = self.classifier(x)\n",
    "        probas = F.softmax(outputs, dim=1)\n",
    "        return outputs, probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and optimizer\n",
    "- Instantiate the model\n",
    "- define the specific Loss function to be used either cross entropy, MSELoss, etc\n",
    "- define the optimization algorithm to be used either SGD, Adam, RMSprop, Momentum etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = LeNet5(NUM_CLASSES, GRAYSCALE).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute accuracy\n",
    "- A function to compute train and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader):\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    for features, labels in data_loader:\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output, probas = model(features)\n",
    "        _,predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += labels.size(0)\n",
    "        correct_predictions += (predicted_labels == labels).sum()\n",
    "    return correct_predictions.float() / num_examples *100\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a model requires the following steps\n",
    "- Reset all the gradients to zero (0)\n",
    "- Make a forward pass (make a prediction)\n",
    "- Calculate the loss\n",
    "- Perform back propagation\n",
    "- Update all the parameters (weight and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch: 000/391 | Cost:2.3059\n",
      "Epoch: 001/010 | Batch: 050/391 | Cost:2.0546\n",
      "Epoch: 001/010 | Batch: 100/391 | Cost:1.8614\n",
      "Epoch: 001/010 | Batch: 150/391 | Cost:1.7192\n",
      "Epoch: 001/010 | Batch: 200/391 | Cost:1.5598\n",
      "Epoch: 001/010 | Batch: 250/391 | Cost:1.4637\n",
      "Epoch: 001/010 | Batch: 300/391 | Cost:1.4403\n",
      "Epoch: 001/010 | Batch: 350/391 | Cost:1.4144\n",
      "Epoch: 001/010 training accuracy: 47.29%\n",
      "Time Elapsed: 1.61 min\n",
      "Epoch: 002/010 | Batch: 000/391 | Cost:1.4807\n",
      "Epoch: 002/010 | Batch: 050/391 | Cost:1.3707\n",
      "Epoch: 002/010 | Batch: 100/391 | Cost:1.3756\n",
      "Epoch: 002/010 | Batch: 150/391 | Cost:1.3793\n",
      "Epoch: 002/010 | Batch: 200/391 | Cost:1.4210\n",
      "Epoch: 002/010 | Batch: 250/391 | Cost:1.3806\n",
      "Epoch: 002/010 | Batch: 300/391 | Cost:1.3048\n",
      "Epoch: 002/010 | Batch: 350/391 | Cost:1.1524\n",
      "Epoch: 002/010 training accuracy: 55.50%\n",
      "Time Elapsed: 3.31 min\n",
      "Epoch: 003/010 | Batch: 000/391 | Cost:1.2437\n",
      "Epoch: 003/010 | Batch: 050/391 | Cost:1.2798\n",
      "Epoch: 003/010 | Batch: 100/391 | Cost:1.3049\n",
      "Epoch: 003/010 | Batch: 150/391 | Cost:1.2441\n",
      "Epoch: 003/010 | Batch: 200/391 | Cost:1.1300\n",
      "Epoch: 003/010 | Batch: 250/391 | Cost:0.9247\n",
      "Epoch: 003/010 | Batch: 300/391 | Cost:1.1203\n",
      "Epoch: 003/010 | Batch: 350/391 | Cost:1.2408\n",
      "Epoch: 003/010 training accuracy: 61.29%\n",
      "Time Elapsed: 5.05 min\n",
      "Epoch: 004/010 | Batch: 000/391 | Cost:1.1336\n",
      "Epoch: 004/010 | Batch: 050/391 | Cost:1.1273\n",
      "Epoch: 004/010 | Batch: 100/391 | Cost:1.0777\n",
      "Epoch: 004/010 | Batch: 150/391 | Cost:1.0971\n",
      "Epoch: 004/010 | Batch: 200/391 | Cost:0.8616\n",
      "Epoch: 004/010 | Batch: 250/391 | Cost:1.1669\n",
      "Epoch: 004/010 | Batch: 300/391 | Cost:0.8691\n",
      "Epoch: 004/010 | Batch: 350/391 | Cost:1.2761\n",
      "Epoch: 004/010 training accuracy: 64.00%\n",
      "Time Elapsed: 6.75 min\n",
      "Epoch: 005/010 | Batch: 000/391 | Cost:1.2191\n",
      "Epoch: 005/010 | Batch: 050/391 | Cost:1.0174\n",
      "Epoch: 005/010 | Batch: 100/391 | Cost:0.8872\n",
      "Epoch: 005/010 | Batch: 150/391 | Cost:0.8472\n",
      "Epoch: 005/010 | Batch: 200/391 | Cost:0.9791\n",
      "Epoch: 005/010 | Batch: 250/391 | Cost:1.0031\n",
      "Epoch: 005/010 | Batch: 300/391 | Cost:1.0139\n",
      "Epoch: 005/010 | Batch: 350/391 | Cost:0.9810\n",
      "Epoch: 005/010 training accuracy: 68.63%\n",
      "Time Elapsed: 8.47 min\n",
      "Epoch: 006/010 | Batch: 000/391 | Cost:0.7735\n",
      "Epoch: 006/010 | Batch: 050/391 | Cost:0.7201\n",
      "Epoch: 006/010 | Batch: 100/391 | Cost:0.8013\n",
      "Epoch: 006/010 | Batch: 150/391 | Cost:0.8693\n",
      "Epoch: 006/010 | Batch: 200/391 | Cost:0.8105\n",
      "Epoch: 006/010 | Batch: 250/391 | Cost:1.0859\n",
      "Epoch: 006/010 | Batch: 300/391 | Cost:0.9364\n",
      "Epoch: 006/010 | Batch: 350/391 | Cost:0.9431\n",
      "Epoch: 006/010 training accuracy: 71.32%\n",
      "Time Elapsed: 10.20 min\n",
      "Epoch: 007/010 | Batch: 000/391 | Cost:0.9186\n",
      "Epoch: 007/010 | Batch: 050/391 | Cost:0.9000\n",
      "Epoch: 007/010 | Batch: 100/391 | Cost:0.6869\n",
      "Epoch: 007/010 | Batch: 150/391 | Cost:0.7708\n",
      "Epoch: 007/010 | Batch: 200/391 | Cost:0.8274\n",
      "Epoch: 007/010 | Batch: 250/391 | Cost:0.6758\n",
      "Epoch: 007/010 | Batch: 300/391 | Cost:0.7584\n",
      "Epoch: 007/010 | Batch: 350/391 | Cost:0.9233\n",
      "Epoch: 007/010 training accuracy: 73.80%\n",
      "Time Elapsed: 11.99 min\n",
      "Epoch: 008/010 | Batch: 000/391 | Cost:0.6584\n",
      "Epoch: 008/010 | Batch: 050/391 | Cost:0.6593\n",
      "Epoch: 008/010 | Batch: 100/391 | Cost:0.7554\n",
      "Epoch: 008/010 | Batch: 150/391 | Cost:0.7842\n",
      "Epoch: 008/010 | Batch: 200/391 | Cost:0.6834\n",
      "Epoch: 008/010 | Batch: 250/391 | Cost:0.7615\n",
      "Epoch: 008/010 | Batch: 300/391 | Cost:0.7351\n",
      "Epoch: 008/010 | Batch: 350/391 | Cost:0.8940\n",
      "Epoch: 008/010 training accuracy: 75.57%\n",
      "Time Elapsed: 13.69 min\n",
      "Epoch: 009/010 | Batch: 000/391 | Cost:0.6769\n",
      "Epoch: 009/010 | Batch: 050/391 | Cost:0.6681\n",
      "Epoch: 009/010 | Batch: 100/391 | Cost:0.7730\n",
      "Epoch: 009/010 | Batch: 150/391 | Cost:0.6308\n",
      "Epoch: 009/010 | Batch: 200/391 | Cost:0.7826\n",
      "Epoch: 009/010 | Batch: 250/391 | Cost:0.7851\n",
      "Epoch: 009/010 | Batch: 300/391 | Cost:0.6982\n",
      "Epoch: 009/010 | Batch: 350/391 | Cost:0.7076\n",
      "Epoch: 009/010 training accuracy: 77.07%\n",
      "Time Elapsed: 15.38 min\n",
      "Epoch: 010/010 | Batch: 000/391 | Cost:0.6674\n",
      "Epoch: 010/010 | Batch: 050/391 | Cost:0.5691\n",
      "Epoch: 010/010 | Batch: 100/391 | Cost:0.6559\n",
      "Epoch: 010/010 | Batch: 150/391 | Cost:0.6303\n",
      "Epoch: 010/010 | Batch: 200/391 | Cost:0.7433\n",
      "Epoch: 010/010 | Batch: 250/391 | Cost:0.6870\n",
      "Epoch: 010/010 | Batch: 300/391 | Cost:0.7101\n",
      "Epoch: 010/010 | Batch: 350/391 | Cost:0.7273\n",
      "Epoch: 010/010 training accuracy: 82.17%\n",
      "Time Elapsed: 17.08 min\n",
      "Total Training Time: 17.08 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward and back pass\n",
    "        output, probas = model(features)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Logging\n",
    "        if not i % 50:\n",
    "            print('Epoch: %03d/%03d | Batch: %03d/%03d | Cost:%.4f'\n",
    "                 %(epoch+1, NUM_EPOCHS, i, total_step, loss))\n",
    "    model.eval()\n",
    "    print('Epoch: %03d/%03d training accuracy: %.2f%%' %(\n",
    "    epoch+1, NUM_EPOCHS, compute_accuracy(model, train_loader)))\n",
    "    print('Time Elapsed: %.2f min' %((time.time() - start_time) / 60 ))\n",
    "print('Total Training Time: %.2f min' %((time.time() - start_time) / 60 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy tensor(68.2400)\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False):\n",
    "    print('Test accuracy', compute_accuracy(model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
