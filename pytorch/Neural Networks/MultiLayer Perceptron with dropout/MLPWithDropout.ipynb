{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project: A multilayer perceptron for multi-class classfication and Applying Droupout Regularization technique.\n",
    "\n",
    "Dropout: This is a regularization techniques used to improve an overfitting model(high variance) by droping off some nodes and links that doesn't participate in the training rocess then taining the model with the remaining hidden nodes and node units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages selection\n",
    "- The first things is to import all the neccesary packages needed for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# select GPU when cuda is available\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings\n",
    "- Configure the device\n",
    "- define all the hyperparameters to be used and needs to be tuned to achive a better accuracy\n",
    "- Load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimension torch.Size([64, 1, 28, 28])\n",
      "Image label dimension torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "random_seed = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "dropout_prob = 0.5\n",
    "\n",
    "# Model Architecture parameters\n",
    "num_features = 784\n",
    "num_hidden_1 = 128\n",
    "num_hidden_2 = 256\n",
    "num_classes = 10\n",
    "\n",
    "# dataset -> MNIST\n",
    "# Note: transform.ToTensor() scale image image to 0-1 range\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data',\n",
    "                              train=True,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data',\n",
    "                             train=False,\n",
    "                             transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)\n",
    "\n",
    "# check the dataset\n",
    "for images, labels in train_loader:\n",
    "    print(\"Image batch dimension\", images.shape)\n",
    "    print(\"Image label dimension\", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the architecture of the model such as\n",
    "- The number of input layers; which is determined by the features of the data\n",
    "- Number of total hidden layers in the model (iterative)\n",
    "of hidden units in each layers (iterative)\n",
    "- The output layer node units is determined by the intended outcome to achieve\n",
    "- Here: we build a 3 layers multilayer perceptron i.e 2 hidden layers and 1 output layer\n",
    "- Note: We don't count the input layer as part of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Architecture:\n",
    "X -> Linear -> Relu -> dropout -> Linear -> Relu -> dropout -> Linear -> Softmax Layer -> y\n",
    "\"\"\"\n",
    "\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "        \n",
    "        # 1st hidden layer\n",
    "        self.linear_1 = torch.nn.Linear(num_features, num_hidden_1)\n",
    "        \n",
    "        # 2nd hidden layer\n",
    "        self.linear_2 = torch.nn.Linear(num_hidden_1, num_hidden_2)\n",
    "        \n",
    "        # output layer\n",
    "        self.linear_out = torch.nn.Linear(num_hidden_2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Link all the layers together\n",
    "        \"\"\"\n",
    "        out = self.linear_1(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=dropout_prob, training=self.training)\n",
    "        \n",
    "        out = self.linear_2(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=dropout_prob, training=self.training)\n",
    "        \n",
    "        outputs = self.linear_out(out)\n",
    "        probas = F.softmax(outputs, dim=1)\n",
    "        return outputs, probas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and optimizer\n",
    "- Instantiate the model\n",
    "- define the specific Loss function to be used either cross entropy, MSELoss, etc\n",
    "- define the optimization algorithm to be used either SGD, Adam, RMSprop, Momentum etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "model = MultiLayerPerceptron(num_features, num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute accuracy\n",
    "- A function to compute train and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct_prediction, num_examples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in data_loader:\n",
    "            features = features.view(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs, probas = model(features)\n",
    "            _, predicted_labels = torch.max(probas, 1)\n",
    "            num_examples +=labels.size(0)\n",
    "            correct_prediction += (predicted_labels == labels).sum()\n",
    "        return correct_prediction.float() / num_examples * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a model requires the following stepsÂ¶\n",
    "- Reset all the gradients to zero (0)\n",
    "- Make a forward pass (make a prediction)\n",
    "- Calculate the loss\n",
    "- Perform back propagation\n",
    "- Update all the parameters (weight and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch: 000/938 | Cost: 2.3000\n",
      "Epoch: 001/010 | Batch: 050/938 | Cost: 0.9042\n",
      "Epoch: 001/010 | Batch: 100/938 | Cost: 0.5057\n",
      "Epoch: 001/010 | Batch: 150/938 | Cost: 0.5168\n",
      "Epoch: 001/010 | Batch: 200/938 | Cost: 0.3971\n",
      "Epoch: 001/010 | Batch: 250/938 | Cost: 0.3894\n",
      "Epoch: 001/010 | Batch: 300/938 | Cost: 0.4434\n",
      "Epoch: 001/010 | Batch: 350/938 | Cost: 0.1512\n",
      "Epoch: 001/010 | Batch: 400/938 | Cost: 0.2976\n",
      "Epoch: 001/010 | Batch: 450/938 | Cost: 0.2695\n",
      "Epoch: 001/010 | Batch: 500/938 | Cost: 0.3153\n",
      "Epoch: 001/010 | Batch: 550/938 | Cost: 0.2600\n",
      "Epoch: 001/010 | Batch: 600/938 | Cost: 0.1263\n",
      "Epoch: 001/010 | Batch: 650/938 | Cost: 0.4475\n",
      "Epoch: 001/010 | Batch: 700/938 | Cost: 0.3200\n",
      "Epoch: 001/010 | Batch: 750/938 | Cost: 0.4549\n",
      "Epoch: 001/010 | Batch: 800/938 | Cost: 0.1912\n",
      "Epoch: 001/010 | Batch: 850/938 | Cost: 0.1499\n",
      "Epoch: 001/010 | Batch: 900/938 | Cost: 0.2598\n",
      "Epoch: 001/010 training accuracy: 94.60%\n",
      "Time elapsed: 0.34 min \n",
      "Epoch: 002/010 | Batch: 000/938 | Cost: 0.1510\n",
      "Epoch: 002/010 | Batch: 050/938 | Cost: 0.1239\n",
      "Epoch: 002/010 | Batch: 100/938 | Cost: 0.1671\n",
      "Epoch: 002/010 | Batch: 150/938 | Cost: 0.0719\n",
      "Epoch: 002/010 | Batch: 200/938 | Cost: 0.0971\n",
      "Epoch: 002/010 | Batch: 250/938 | Cost: 0.1551\n",
      "Epoch: 002/010 | Batch: 300/938 | Cost: 0.2357\n",
      "Epoch: 002/010 | Batch: 350/938 | Cost: 0.1854\n",
      "Epoch: 002/010 | Batch: 400/938 | Cost: 0.1167\n",
      "Epoch: 002/010 | Batch: 450/938 | Cost: 0.1201\n",
      "Epoch: 002/010 | Batch: 500/938 | Cost: 0.1602\n",
      "Epoch: 002/010 | Batch: 550/938 | Cost: 0.0824\n",
      "Epoch: 002/010 | Batch: 600/938 | Cost: 0.0781\n",
      "Epoch: 002/010 | Batch: 650/938 | Cost: 0.1384\n",
      "Epoch: 002/010 | Batch: 700/938 | Cost: 0.1292\n",
      "Epoch: 002/010 | Batch: 750/938 | Cost: 0.0073\n",
      "Epoch: 002/010 | Batch: 800/938 | Cost: 0.3157\n",
      "Epoch: 002/010 | Batch: 850/938 | Cost: 0.1154\n",
      "Epoch: 002/010 | Batch: 900/938 | Cost: 0.0862\n",
      "Epoch: 002/010 training accuracy: 97.36%\n",
      "Time elapsed: 0.75 min \n",
      "Epoch: 003/010 | Batch: 000/938 | Cost: 0.1510\n",
      "Epoch: 003/010 | Batch: 050/938 | Cost: 0.0733\n",
      "Epoch: 003/010 | Batch: 100/938 | Cost: 0.0449\n",
      "Epoch: 003/010 | Batch: 150/938 | Cost: 0.2750\n",
      "Epoch: 003/010 | Batch: 200/938 | Cost: 0.1074\n",
      "Epoch: 003/010 | Batch: 250/938 | Cost: 0.0782\n",
      "Epoch: 003/010 | Batch: 300/938 | Cost: 0.0179\n",
      "Epoch: 003/010 | Batch: 350/938 | Cost: 0.0258\n",
      "Epoch: 003/010 | Batch: 400/938 | Cost: 0.1137\n",
      "Epoch: 003/010 | Batch: 450/938 | Cost: 0.2084\n",
      "Epoch: 003/010 | Batch: 500/938 | Cost: 0.0321\n",
      "Epoch: 003/010 | Batch: 550/938 | Cost: 0.1026\n",
      "Epoch: 003/010 | Batch: 600/938 | Cost: 0.0624\n",
      "Epoch: 003/010 | Batch: 650/938 | Cost: 0.1855\n",
      "Epoch: 003/010 | Batch: 700/938 | Cost: 0.2475\n",
      "Epoch: 003/010 | Batch: 750/938 | Cost: 0.0492\n",
      "Epoch: 003/010 | Batch: 800/938 | Cost: 0.0794\n",
      "Epoch: 003/010 | Batch: 850/938 | Cost: 0.1813\n",
      "Epoch: 003/010 | Batch: 900/938 | Cost: 0.0250\n",
      "Epoch: 003/010 training accuracy: 98.21%\n",
      "Time elapsed: 1.18 min \n",
      "Epoch: 004/010 | Batch: 000/938 | Cost: 0.0609\n",
      "Epoch: 004/010 | Batch: 050/938 | Cost: 0.1052\n",
      "Epoch: 004/010 | Batch: 100/938 | Cost: 0.0285\n",
      "Epoch: 004/010 | Batch: 150/938 | Cost: 0.2092\n",
      "Epoch: 004/010 | Batch: 200/938 | Cost: 0.0588\n",
      "Epoch: 004/010 | Batch: 250/938 | Cost: 0.0071\n",
      "Epoch: 004/010 | Batch: 300/938 | Cost: 0.0288\n",
      "Epoch: 004/010 | Batch: 350/938 | Cost: 0.0509\n",
      "Epoch: 004/010 | Batch: 400/938 | Cost: 0.0396\n",
      "Epoch: 004/010 | Batch: 450/938 | Cost: 0.0274\n",
      "Epoch: 004/010 | Batch: 500/938 | Cost: 0.0615\n",
      "Epoch: 004/010 | Batch: 550/938 | Cost: 0.1322\n",
      "Epoch: 004/010 | Batch: 600/938 | Cost: 0.0249\n",
      "Epoch: 004/010 | Batch: 650/938 | Cost: 0.0831\n",
      "Epoch: 004/010 | Batch: 700/938 | Cost: 0.0187\n",
      "Epoch: 004/010 | Batch: 750/938 | Cost: 0.0798\n",
      "Epoch: 004/010 | Batch: 800/938 | Cost: 0.1321\n",
      "Epoch: 004/010 | Batch: 850/938 | Cost: 0.0558\n",
      "Epoch: 004/010 | Batch: 900/938 | Cost: 0.0550\n",
      "Epoch: 004/010 training accuracy: 98.54%\n",
      "Time elapsed: 1.58 min \n",
      "Epoch: 005/010 | Batch: 000/938 | Cost: 0.0327\n",
      "Epoch: 005/010 | Batch: 050/938 | Cost: 0.0435\n",
      "Epoch: 005/010 | Batch: 100/938 | Cost: 0.0299\n",
      "Epoch: 005/010 | Batch: 150/938 | Cost: 0.0792\n",
      "Epoch: 005/010 | Batch: 200/938 | Cost: 0.0306\n",
      "Epoch: 005/010 | Batch: 250/938 | Cost: 0.0163\n",
      "Epoch: 005/010 | Batch: 300/938 | Cost: 0.0171\n",
      "Epoch: 005/010 | Batch: 350/938 | Cost: 0.0347\n",
      "Epoch: 005/010 | Batch: 400/938 | Cost: 0.0227\n",
      "Epoch: 005/010 | Batch: 450/938 | Cost: 0.0228\n",
      "Epoch: 005/010 | Batch: 500/938 | Cost: 0.0424\n",
      "Epoch: 005/010 | Batch: 550/938 | Cost: 0.0331\n",
      "Epoch: 005/010 | Batch: 600/938 | Cost: 0.0391\n",
      "Epoch: 005/010 | Batch: 650/938 | Cost: 0.1200\n",
      "Epoch: 005/010 | Batch: 700/938 | Cost: 0.0353\n",
      "Epoch: 005/010 | Batch: 750/938 | Cost: 0.0263\n",
      "Epoch: 005/010 | Batch: 800/938 | Cost: 0.0852\n",
      "Epoch: 005/010 | Batch: 850/938 | Cost: 0.0456\n",
      "Epoch: 005/010 | Batch: 900/938 | Cost: 0.0244\n",
      "Epoch: 005/010 training accuracy: 98.63%\n",
      "Time elapsed: 1.96 min \n",
      "Epoch: 006/010 | Batch: 000/938 | Cost: 0.0225\n",
      "Epoch: 006/010 | Batch: 050/938 | Cost: 0.0594\n",
      "Epoch: 006/010 | Batch: 100/938 | Cost: 0.0488\n",
      "Epoch: 006/010 | Batch: 150/938 | Cost: 0.0411\n",
      "Epoch: 006/010 | Batch: 200/938 | Cost: 0.0111\n",
      "Epoch: 006/010 | Batch: 250/938 | Cost: 0.0101\n",
      "Epoch: 006/010 | Batch: 300/938 | Cost: 0.0265\n",
      "Epoch: 006/010 | Batch: 350/938 | Cost: 0.0174\n",
      "Epoch: 006/010 | Batch: 400/938 | Cost: 0.0628\n",
      "Epoch: 006/010 | Batch: 450/938 | Cost: 0.0165\n",
      "Epoch: 006/010 | Batch: 500/938 | Cost: 0.0131\n",
      "Epoch: 006/010 | Batch: 550/938 | Cost: 0.0368\n",
      "Epoch: 006/010 | Batch: 600/938 | Cost: 0.0137\n",
      "Epoch: 006/010 | Batch: 650/938 | Cost: 0.0078\n",
      "Epoch: 006/010 | Batch: 700/938 | Cost: 0.0079\n",
      "Epoch: 006/010 | Batch: 750/938 | Cost: 0.0061\n",
      "Epoch: 006/010 | Batch: 800/938 | Cost: 0.0201\n",
      "Epoch: 006/010 | Batch: 850/938 | Cost: 0.0411\n",
      "Epoch: 006/010 | Batch: 900/938 | Cost: 0.0359\n",
      "Epoch: 006/010 training accuracy: 99.23%\n",
      "Time elapsed: 2.34 min \n",
      "Epoch: 007/010 | Batch: 000/938 | Cost: 0.0300\n",
      "Epoch: 007/010 | Batch: 050/938 | Cost: 0.0624\n",
      "Epoch: 007/010 | Batch: 100/938 | Cost: 0.0033\n",
      "Epoch: 007/010 | Batch: 150/938 | Cost: 0.0393\n",
      "Epoch: 007/010 | Batch: 200/938 | Cost: 0.0007\n",
      "Epoch: 007/010 | Batch: 250/938 | Cost: 0.0030\n",
      "Epoch: 007/010 | Batch: 300/938 | Cost: 0.0008\n",
      "Epoch: 007/010 | Batch: 350/938 | Cost: 0.0355\n",
      "Epoch: 007/010 | Batch: 400/938 | Cost: 0.0121\n",
      "Epoch: 007/010 | Batch: 450/938 | Cost: 0.0109\n",
      "Epoch: 007/010 | Batch: 500/938 | Cost: 0.0031\n",
      "Epoch: 007/010 | Batch: 550/938 | Cost: 0.0288\n",
      "Epoch: 007/010 | Batch: 600/938 | Cost: 0.0147\n",
      "Epoch: 007/010 | Batch: 650/938 | Cost: 0.0220\n",
      "Epoch: 007/010 | Batch: 700/938 | Cost: 0.0657\n",
      "Epoch: 007/010 | Batch: 750/938 | Cost: 0.0081\n",
      "Epoch: 007/010 | Batch: 800/938 | Cost: 0.0047\n",
      "Epoch: 007/010 | Batch: 850/938 | Cost: 0.0103\n",
      "Epoch: 007/010 | Batch: 900/938 | Cost: 0.1771\n",
      "Epoch: 007/010 training accuracy: 99.25%\n",
      "Time elapsed: 2.74 min \n",
      "Epoch: 008/010 | Batch: 000/938 | Cost: 0.0505\n",
      "Epoch: 008/010 | Batch: 050/938 | Cost: 0.0527\n",
      "Epoch: 008/010 | Batch: 100/938 | Cost: 0.0086\n",
      "Epoch: 008/010 | Batch: 150/938 | Cost: 0.0131\n",
      "Epoch: 008/010 | Batch: 200/938 | Cost: 0.0082\n",
      "Epoch: 008/010 | Batch: 250/938 | Cost: 0.0779\n",
      "Epoch: 008/010 | Batch: 300/938 | Cost: 0.0020\n",
      "Epoch: 008/010 | Batch: 350/938 | Cost: 0.0099\n",
      "Epoch: 008/010 | Batch: 400/938 | Cost: 0.0111\n",
      "Epoch: 008/010 | Batch: 450/938 | Cost: 0.0101\n",
      "Epoch: 008/010 | Batch: 500/938 | Cost: 0.0238\n",
      "Epoch: 008/010 | Batch: 550/938 | Cost: 0.0432\n",
      "Epoch: 008/010 | Batch: 600/938 | Cost: 0.0237\n",
      "Epoch: 008/010 | Batch: 650/938 | Cost: 0.0138\n",
      "Epoch: 008/010 | Batch: 700/938 | Cost: 0.0006\n",
      "Epoch: 008/010 | Batch: 750/938 | Cost: 0.0129\n",
      "Epoch: 008/010 | Batch: 800/938 | Cost: 0.0026\n",
      "Epoch: 008/010 | Batch: 850/938 | Cost: 0.0439\n",
      "Epoch: 008/010 | Batch: 900/938 | Cost: 0.0068\n",
      "Epoch: 008/010 training accuracy: 99.33%\n",
      "Time elapsed: 3.13 min \n",
      "Epoch: 009/010 | Batch: 000/938 | Cost: 0.0236\n",
      "Epoch: 009/010 | Batch: 050/938 | Cost: 0.0642\n",
      "Epoch: 009/010 | Batch: 100/938 | Cost: 0.0012\n",
      "Epoch: 009/010 | Batch: 150/938 | Cost: 0.0379\n",
      "Epoch: 009/010 | Batch: 200/938 | Cost: 0.0131\n",
      "Epoch: 009/010 | Batch: 250/938 | Cost: 0.0009\n",
      "Epoch: 009/010 | Batch: 300/938 | Cost: 0.1185\n",
      "Epoch: 009/010 | Batch: 350/938 | Cost: 0.0070\n",
      "Epoch: 009/010 | Batch: 400/938 | Cost: 0.0249\n",
      "Epoch: 009/010 | Batch: 450/938 | Cost: 0.0077\n",
      "Epoch: 009/010 | Batch: 500/938 | Cost: 0.0020\n",
      "Epoch: 009/010 | Batch: 550/938 | Cost: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009/010 | Batch: 600/938 | Cost: 0.0029\n",
      "Epoch: 009/010 | Batch: 650/938 | Cost: 0.0098\n",
      "Epoch: 009/010 | Batch: 700/938 | Cost: 0.0561\n",
      "Epoch: 009/010 | Batch: 750/938 | Cost: 0.0151\n",
      "Epoch: 009/010 | Batch: 800/938 | Cost: 0.0034\n",
      "Epoch: 009/010 | Batch: 850/938 | Cost: 0.0431\n",
      "Epoch: 009/010 | Batch: 900/938 | Cost: 0.0694\n",
      "Epoch: 009/010 training accuracy: 99.29%\n",
      "Time elapsed: 3.55 min \n",
      "Epoch: 010/010 | Batch: 000/938 | Cost: 0.0041\n",
      "Epoch: 010/010 | Batch: 050/938 | Cost: 0.0072\n",
      "Epoch: 010/010 | Batch: 100/938 | Cost: 0.0072\n",
      "Epoch: 010/010 | Batch: 150/938 | Cost: 0.0057\n",
      "Epoch: 010/010 | Batch: 200/938 | Cost: 0.0104\n",
      "Epoch: 010/010 | Batch: 250/938 | Cost: 0.0013\n",
      "Epoch: 010/010 | Batch: 300/938 | Cost: 0.0008\n",
      "Epoch: 010/010 | Batch: 350/938 | Cost: 0.0028\n",
      "Epoch: 010/010 | Batch: 400/938 | Cost: 0.0012\n",
      "Epoch: 010/010 | Batch: 450/938 | Cost: 0.0165\n",
      "Epoch: 010/010 | Batch: 500/938 | Cost: 0.0020\n",
      "Epoch: 010/010 | Batch: 550/938 | Cost: 0.0203\n",
      "Epoch: 010/010 | Batch: 600/938 | Cost: 0.0026\n",
      "Epoch: 010/010 | Batch: 650/938 | Cost: 0.0284\n",
      "Epoch: 010/010 | Batch: 700/938 | Cost: 0.0926\n",
      "Epoch: 010/010 | Batch: 750/938 | Cost: 0.0142\n",
      "Epoch: 010/010 | Batch: 800/938 | Cost: 0.0047\n",
      "Epoch: 010/010 | Batch: 850/938 | Cost: 0.0203\n",
      "Epoch: 010/010 | Batch: 900/938 | Cost: 0.0029\n",
      "Epoch: 010/010 training accuracy: 99.49%\n",
      "Time elapsed: 3.94 min \n",
      "Total training Time: 3.94 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward and Back Pass\n",
    "        outputs, probas = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Logging\n",
    "        if not i % 50:\n",
    "            print('Epoch: %03d/%03d | Batch: %03d/%03d | Cost: %.4f'\n",
    "                 %(epoch+1, num_epochs, i, total_step, loss))\n",
    "    print('Epoch: %03d/%03d training accuracy: %.2f%%' % (\n",
    "    epoch+1, num_epochs, compute_accuracy(model, train_loader)))\n",
    "    \n",
    "    print('Time elapsed: %.2f min ' % ((time.time() - start_time) / 60))\n",
    "    \n",
    "print('Total training Time: %.2f min' % ((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.72%\n"
     ]
    }
   ],
   "source": [
    "# print the test accuracy\n",
    "print(\"Test Accuracy: %.2f%%\" % (compute_accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
