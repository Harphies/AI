{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the train and test set\n",
    "train_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n",
    "train_set = np.array(train_set,dtype = 'int')\n",
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
    "test_set = np.array(test_set, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total number of users and movies in the database\n",
    "nb_users = int(max(max(train_set[:,0]), max(test_set[:,0])))\n",
    "nb_movies = int(max(max(train_set[:,1]), max(test_set[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data into an array with users in rows and movies in coulmums \n",
    "\n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users +1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "train_set = convert(train_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data into torch tensor\n",
    "train_set = torch.FloatTensor(train_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1loss:150.94560038065538\n",
      "epoch:2loss:58.26462555862963\n",
      "epoch:3loss:53.457291351864114\n",
      "epoch:4loss:51.76683685788885\n",
      "epoch:5loss:50.96671332651749\n",
      "epoch:6loss:50.495222518453375\n",
      "epoch:7loss:50.185861349571496\n",
      "epoch:8loss:50.00222263089381\n",
      "epoch:9loss:49.87872382882051\n",
      "epoch:10loss:49.76085396425333\n",
      "epoch:11loss:49.687861835816875\n",
      "epoch:12loss:49.63344586559106\n",
      "epoch:13loss:49.60119485144969\n",
      "epoch:14loss:49.55087251320947\n",
      "epoch:15loss:49.55050618969835\n",
      "epoch:16loss:49.485379446763545\n",
      "epoch:17loss:49.481970206368715\n",
      "epoch:18loss:49.430195577209815\n",
      "epoch:19loss:49.43802142387722\n",
      "epoch:20loss:49.40070888772607\n",
      "epoch:21loss:49.41402411973104\n",
      "epoch:22loss:49.38448932021856\n",
      "epoch:23loss:49.388632896123454\n",
      "epoch:24loss:49.35826215078123\n",
      "epoch:25loss:49.3688422201667\n",
      "epoch:26loss:49.34111655084416\n",
      "epoch:27loss:49.33578240475617\n",
      "epoch:28loss:49.30102851532865\n",
      "epoch:29loss:48.97761042509228\n",
      "epoch:30loss:48.85038861411158\n",
      "epoch:31loss:48.37506943929475\n",
      "epoch:32loss:48.492023854050785\n",
      "epoch:33loss:47.60937570326496\n",
      "epoch:34loss:47.88160479837097\n",
      "epoch:35loss:46.83942337729968\n",
      "epoch:36loss:46.83219873846974\n",
      "epoch:37loss:46.21418939996511\n",
      "epoch:38loss:45.93182506982703\n",
      "epoch:39loss:45.78066577273421\n",
      "epoch:40loss:45.647508973954245\n",
      "epoch:41loss:45.29736139590386\n",
      "epoch:42loss:45.409914610441774\n",
      "epoch:43loss:45.31538981513586\n",
      "epoch:44loss:45.11179503489984\n",
      "epoch:45loss:45.25475308421301\n",
      "epoch:46loss:45.60450269281864\n",
      "epoch:47loss:45.28033904649783\n",
      "epoch:48loss:44.7316695820773\n",
      "epoch:49loss:44.56479655124713\n",
      "epoch:50loss:44.27542787900893\n",
      "epoch:51loss:44.117607974098064\n",
      "epoch:52loss:44.11664180958178\n",
      "epoch:53loss:45.35384346358478\n",
      "epoch:54loss:45.189851372269914\n",
      "epoch:55loss:46.06880158302374\n",
      "epoch:56loss:45.533165890024975\n",
      "epoch:57loss:45.74327448767144\n",
      "epoch:58loss:45.504095560114365\n",
      "epoch:59loss:45.18699773272965\n",
      "epoch:60loss:44.63848035252886\n",
      "epoch:61loss:44.33064945979277\n",
      "epoch:62loss:44.27952814823948\n",
      "epoch:63loss:44.26227860071231\n",
      "epoch:64loss:45.54059743753169\n",
      "epoch:65loss:45.588236107316334\n",
      "epoch:66loss:45.58507307805121\n",
      "epoch:67loss:44.87717330036685\n",
      "epoch:68loss:45.32154270343017\n",
      "epoch:69loss:45.262125745241065\n",
      "epoch:70loss:44.39264766999986\n",
      "epoch:71loss:43.77468351239804\n",
      "epoch:72loss:43.57896892231656\n",
      "epoch:73loss:43.362852145859506\n",
      "epoch:74loss:43.88961622084025\n",
      "epoch:75loss:43.67605084361276\n",
      "epoch:76loss:42.978483931394294\n",
      "epoch:77loss:43.8815494683804\n",
      "epoch:78loss:43.5090566953877\n",
      "epoch:79loss:43.08639982261229\n",
      "epoch:80loss:42.98844252631534\n",
      "epoch:81loss:42.75744878750993\n",
      "epoch:82loss:42.90900731284637\n",
      "epoch:83loss:42.60592565353727\n",
      "epoch:84loss:42.98731592588592\n",
      "epoch:85loss:42.78146967000794\n",
      "epoch:86loss:42.473208181443624\n",
      "epoch:87loss:42.613258070196025\n",
      "epoch:88loss:42.895722793997265\n",
      "epoch:89loss:42.78766907082172\n",
      "epoch:90loss:42.719464340247214\n",
      "epoch:91loss:42.46415166259976\n",
      "epoch:92loss:42.62237421364989\n",
      "epoch:93loss:42.396688971086405\n",
      "epoch:94loss:43.74271260906244\n",
      "epoch:95loss:43.6427411075565\n",
      "epoch:96loss:43.54429517209064\n",
      "epoch:97loss:43.261599729186855\n",
      "epoch:98loss:43.29147961369017\n",
      "epoch:99loss:43.29850798792904\n",
      "epoch:100loss:43.287394359649625\n",
      "epoch:101loss:42.902860296773724\n",
      "epoch:102loss:43.22406075510662\n",
      "epoch:103loss:42.673749307286926\n",
      "epoch:104loss:42.82394103554543\n",
      "epoch:105loss:42.578922673419584\n",
      "epoch:106loss:42.5441087547224\n",
      "epoch:107loss:42.82650490151718\n",
      "epoch:108loss:42.49114154971903\n",
      "epoch:109loss:42.27622623316711\n",
      "epoch:110loss:43.49312737566652\n",
      "epoch:111loss:42.889896448585205\n",
      "epoch:112loss:42.60475232184399\n",
      "epoch:113loss:42.765176635060925\n",
      "epoch:114loss:42.19114462466678\n",
      "epoch:115loss:42.41449090029346\n",
      "epoch:116loss:42.087560795713216\n",
      "epoch:117loss:41.853470084199216\n",
      "epoch:118loss:42.11528956395341\n",
      "epoch:119loss:41.83050391898723\n",
      "epoch:120loss:41.86447584728012\n",
      "epoch:121loss:41.715068806137424\n",
      "epoch:122loss:41.823376521933824\n",
      "epoch:123loss:41.808440788357984\n",
      "epoch:124loss:41.82570324157132\n",
      "epoch:125loss:41.600687589205336\n",
      "epoch:126loss:41.79056386312004\n",
      "epoch:127loss:41.87352590286173\n",
      "epoch:128loss:41.78763591131428\n",
      "epoch:129loss:41.69147906760918\n",
      "epoch:130loss:41.58702427853132\n",
      "epoch:131loss:41.50641847914085\n",
      "epoch:132loss:41.58079499239102\n",
      "epoch:133loss:41.521848525619134\n",
      "epoch:134loss:41.56368497473886\n",
      "epoch:135loss:41.35291267198045\n",
      "epoch:136loss:41.52756948483875\n",
      "epoch:137loss:41.398259683162905\n",
      "epoch:138loss:41.49585165042663\n",
      "epoch:139loss:41.29112609522417\n",
      "epoch:140loss:41.61785367835546\n",
      "epoch:141loss:41.30223767639836\n",
      "epoch:142loss:41.396554851089604\n",
      "epoch:143loss:41.25553090299945\n",
      "epoch:144loss:41.31146563362563\n",
      "epoch:145loss:41.23336003680015\n",
      "epoch:146loss:41.26709685620153\n",
      "epoch:147loss:41.120259626593906\n",
      "epoch:148loss:41.1837105716113\n",
      "epoch:149loss:41.07656747318106\n",
      "epoch:150loss:41.17999995453283\n",
      "epoch:151loss:41.078458224306814\n",
      "epoch:152loss:41.15302292932756\n",
      "epoch:153loss:41.08385343523696\n",
      "epoch:154loss:41.10390049550915\n",
      "epoch:155loss:41.01188743003877\n",
      "epoch:156loss:41.076399787154514\n",
      "epoch:157loss:40.96835537836887\n",
      "epoch:158loss:41.01299100223696\n",
      "epoch:159loss:40.95424732158426\n",
      "epoch:160loss:41.011220148939174\n",
      "epoch:161loss:40.87650666065747\n",
      "epoch:162loss:40.94429244584171\n",
      "epoch:163loss:40.859643357631285\n",
      "epoch:164loss:40.93754825129872\n",
      "epoch:165loss:40.86969488800969\n",
      "epoch:166loss:40.94935554021504\n",
      "epoch:167loss:40.79123707866529\n",
      "epoch:168loss:40.89699112152448\n",
      "epoch:169loss:40.780304891988635\n",
      "epoch:170loss:40.86346991005121\n",
      "epoch:171loss:40.78296061308356\n",
      "epoch:172loss:40.86070636595832\n",
      "epoch:173loss:40.74804359523114\n",
      "epoch:174loss:40.85390920442296\n",
      "epoch:175loss:40.726849181519356\n",
      "epoch:176loss:40.815946369606536\n",
      "epoch:177loss:40.78101217036601\n",
      "epoch:178loss:40.800375398190226\n",
      "epoch:179loss:40.720407369197346\n",
      "epoch:180loss:40.76852398994379\n",
      "epoch:181loss:40.6570193041116\n",
      "epoch:182loss:40.73135336249834\n",
      "epoch:183loss:40.6268660738715\n",
      "epoch:184loss:40.742177908774465\n",
      "epoch:185loss:40.676504638802726\n",
      "epoch:186loss:40.69508088869043\n",
      "epoch:187loss:40.58800026180688\n",
      "epoch:188loss:40.645192476629745\n",
      "epoch:189loss:40.604399344709236\n",
      "epoch:190loss:40.63986873510294\n",
      "epoch:191loss:40.528217488958035\n",
      "epoch:192loss:40.60545481729787\n",
      "epoch:193loss:40.5727787464275\n",
      "epoch:194loss:40.57447420421522\n",
      "epoch:195loss:40.51663481455762\n",
      "epoch:196loss:40.54593258188106\n",
      "epoch:197loss:40.501211965223774\n",
      "epoch:198loss:40.56330900435569\n",
      "epoch:199loss:40.45865810313262\n",
      "epoch:200loss:40.489883131114766\n",
      "epoch:201loss:40.41867247025948\n",
      "epoch:202loss:40.45010181074031\n",
      "epoch:203loss:40.37586732360069\n",
      "epoch:204loss:40.439865904918406\n",
      "epoch:205loss:40.409028990135994\n",
      "epoch:206loss:40.4361099457019\n",
      "epoch:207loss:40.39919936709339\n",
      "epoch:208loss:40.443745079042856\n",
      "epoch:209loss:40.36815244809259\n",
      "epoch:210loss:40.43826908047777\n",
      "epoch:211loss:40.344075578905176\n",
      "epoch:212loss:40.4072063191561\n",
      "epoch:213loss:40.31135809601983\n",
      "epoch:214loss:40.36844921304146\n",
      "epoch:215loss:40.281022922485135\n",
      "epoch:216loss:40.328031390323304\n",
      "epoch:217loss:40.29842093784828\n",
      "epoch:218loss:40.3535799793317\n",
      "epoch:219loss:40.26661133382004\n",
      "epoch:220loss:40.36084559833398\n",
      "epoch:221loss:40.2342117568478\n",
      "epoch:222loss:40.401294620358385\n",
      "epoch:223loss:40.19987064646557\n",
      "epoch:224loss:40.267924836603925\n",
      "epoch:225loss:40.165806643490214\n",
      "epoch:226loss:41.157026320463046\n",
      "epoch:227loss:40.364389296097215\n",
      "epoch:228loss:40.17953983222833\n",
      "epoch:229loss:40.1024984929245\n",
      "epoch:230loss:40.18487529066624\n",
      "epoch:231loss:40.09550307621248\n",
      "epoch:232loss:40.137743435334414\n",
      "epoch:233loss:40.07535348570673\n",
      "epoch:234loss:40.12417526374338\n",
      "epoch:235loss:40.03892559593078\n",
      "epoch:236loss:40.1155507361982\n",
      "epoch:237loss:40.04332377342507\n",
      "epoch:238loss:40.1161881229491\n",
      "epoch:239loss:40.03880885994295\n",
      "epoch:240loss:40.09434190928005\n",
      "epoch:241loss:39.98507989157224\n",
      "epoch:242loss:40.06666400009999\n",
      "epoch:243loss:40.04158881463809\n",
      "epoch:244loss:40.05269429465989\n",
      "epoch:245loss:39.94018815230811\n",
      "epoch:246loss:40.049203122383915\n",
      "epoch:247loss:39.94291527074529\n",
      "epoch:248loss:40.00878843344981\n",
      "epoch:249loss:39.86176469537895\n",
      "epoch:250loss:39.952608126972336\n",
      "epoch:251loss:39.855737178062554\n",
      "epoch:252loss:39.93232454342069\n",
      "epoch:253loss:39.845990219095256\n",
      "epoch:254loss:39.90752654778771\n",
      "epoch:255loss:39.791813286952674\n",
      "epoch:256loss:39.89614168234402\n",
      "test_loss:0\n"
     ]
    }
   ],
   "source": [
    "# create the architecture of the stacked autoencoder neural network\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_movies, 20)\n",
    "        self.fc2 = nn.Linear(20,10)\n",
    "        self.fc3 = nn.Linear(10,20)\n",
    "        self.fc4 = nn.Linear(20, nb_movies)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "stacked_autoencoder = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(stacked_autoencoder.parameters(), lr=0.01, weight_decay = 0.5)\n",
    "\n",
    "nb_epoch = 256\n",
    "for epoch  in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    # s = 0.\n",
    "    for id_user in range(nb_users):\n",
    "        input_val = Variable(train_set[id_user].unsqueeze(0))\n",
    "        target = input_val.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = stacked_autoencoder(input_val)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target) \n",
    "            # mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            # s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch:' +str(epoch)+ 'loss:' + str(train_loss))\n",
    "\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "\n",
    "for id_users in range(nb_users):\n",
    "    input_val = Variable(train_set[id_users]).unsqueeze(0)\n",
    "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = stacked_autoencoder(input_val)\n",
    "        target.requir_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output,target)\n",
    "        # mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += loss.item()\n",
    "        # s += 1.\n",
    "print('test_loss:' + str(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
