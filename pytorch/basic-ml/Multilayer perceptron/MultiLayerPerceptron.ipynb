{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilayer percepron: A class of fully connected layers also known as FeedForward Neural Networks\n",
    "\n",
    "#####  Feedforward Network:  \n",
    "is a function approximation machine that are designed to achieve statistical generalization, occasionally drawn some insights from what we known about the brain, rather than as models of brain function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages selection\n",
    "- The first things is to import all the neccesary packages needed for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# select GPU when cuda is available\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings\n",
    "- Configure the device\n",
    "- define all the hyperparameters to be used and needs to be tuned to achive a better accuracy\n",
    "- Load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimension torch.Size([64, 1, 28, 28])\n",
      "image lable dimension torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "random_seed = 1 # for generating random number\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 64 #power of 2 is prefferable\n",
    "\n",
    "# Model Architecture parameters\n",
    "num_features = 784 \n",
    "num_hidden_1 = 128 \n",
    "num_hidden_2 = 256\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "# dataset -> MNIST\n",
    "# Note: tranforms.ToTensor() scale images to 0-1 range\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data',\n",
    "                              train=True,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data',\n",
    "                             train=False,\n",
    "                             transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False)\n",
    "\n",
    "# check the dataset\n",
    "for images, labels in train_loader:\n",
    "    print('Image batch dimension', images.shape)\n",
    "    print('image lable dimension', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the architecture of the model such as\n",
    "- The number of input layers; which is determined by the features of the data\n",
    "- Number of total hidden layers in the model (iterative)\n",
    "- Number of hidden units in each layers (iterative)\n",
    "- The output layer node units is determined by the intended outcome to achieve\n",
    "\n",
    "### Here: we build a 3 layers multilayer perceptron i.e 2 hidden layers and 1 output layer\n",
    "#####  Note: We don't count the input layer as part of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Architecture\n",
    "X -> Linear -> Relu -> Linear -> Relu -> Linear -> softmax -> y\n",
    "\"\"\"\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        \n",
    "        \"\"\"\n",
    "        Basic defintion of each layers parameters\n",
    "        \"\"\"\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "        \n",
    "        # 1st Hidden Layer\n",
    "        self.linear_1 = nn.Linear(num_features, num_hidden_1)\n",
    "        \n",
    "        # 2nd Hidden layer\n",
    "        self.linear_2 = nn.Linear(num_hidden_1, num_hidden_2)\n",
    "        \n",
    "        # output layer\n",
    "        self.linear_out = nn.Linear(num_hidden_2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Link all the layers together\n",
    "        \"\"\"\n",
    "        out = self.linear_1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear_2(out)\n",
    "        out = F.relu(out)\n",
    "        outputs = self.linear_out(out)\n",
    "        probas = F.log_softmax(outputs, dim=1)\n",
    "        return outputs, probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and optimizer\n",
    "- Instantiate the model\n",
    "- define the specific Loss function to be used either cross entropy, MSELoss, etc\n",
    "- define the optimization algorithm to be used either SGD, Adam, RMSprop, Momentum et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(random_seed) # generate a random number\n",
    "model = MultiLayerPerceptron(num_features=num_features,\n",
    "                            num_classes=num_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute accuracy\n",
    "- A function to compute train and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(net, data_loader):\n",
    "    net.eval()\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in data_loader:\n",
    "            features = features.view(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs, probas = net(features)\n",
    "            _, predicted_labels = torch.max(probas, 1)\n",
    "            num_examples += labels.size(0)\n",
    "            correct_pred += (predicted_labels == labels).sum()\n",
    "        return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a model requires the following steps\n",
    "- Reset all the gradients to zero (0)\n",
    "- Make a forward pass (make a prediction)\n",
    "- Calculate the loss\n",
    "- Perform back propagation\n",
    "- Update all the parameters (weight and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 000/938 | Loss: 2.3020\n",
      "Epoch: 001/010 | Batch 050/938 | Loss: 2.3212\n",
      "Epoch: 001/010 | Batch 100/938 | Loss: 2.3050\n",
      "Epoch: 001/010 | Batch 150/938 | Loss: 2.3067\n",
      "Epoch: 001/010 | Batch 200/938 | Loss: 2.3141\n",
      "Epoch: 001/010 | Batch 250/938 | Loss: 2.3036\n",
      "Epoch: 001/010 | Batch 300/938 | Loss: 2.2941\n",
      "Epoch: 001/010 | Batch 350/938 | Loss: 2.2889\n",
      "Epoch: 001/010 | Batch 400/938 | Loss: 2.2966\n",
      "Epoch: 001/010 | Batch 450/938 | Loss: 2.2828\n",
      "Epoch: 001/010 | Batch 500/938 | Loss: 2.2982\n",
      "Epoch: 001/010 | Batch 550/938 | Loss: 2.2916\n",
      "Epoch: 001/010 | Batch 600/938 | Loss: 2.2763\n",
      "Epoch: 001/010 | Batch 650/938 | Loss: 2.2769\n",
      "Epoch: 001/010 | Batch 700/938 | Loss: 2.2915\n",
      "Epoch: 001/010 | Batch 750/938 | Loss: 2.2804\n",
      "Epoch: 001/010 | Batch 800/938 | Loss: 2.2850\n",
      "Epoch: 001/010 | Batch 850/938 | Loss: 2.2839\n",
      "Epoch: 001/010 | Batch 900/938 | Loss: 2.2719\n",
      "Epoch: 001/010 training accuracy: 17.34%\n",
      "Time elapsed: 0.32 min\n",
      "Epoch: 002/010 | Batch 000/938 | Loss: 2.2687\n",
      "Epoch: 002/010 | Batch 050/938 | Loss: 2.2821\n",
      "Epoch: 002/010 | Batch 100/938 | Loss: 2.2699\n",
      "Epoch: 002/010 | Batch 150/938 | Loss: 2.2747\n",
      "Epoch: 002/010 | Batch 200/938 | Loss: 2.2832\n",
      "Epoch: 002/010 | Batch 250/938 | Loss: 2.2769\n",
      "Epoch: 002/010 | Batch 300/938 | Loss: 2.2487\n",
      "Epoch: 002/010 | Batch 350/938 | Loss: 2.2520\n",
      "Epoch: 002/010 | Batch 400/938 | Loss: 2.2616\n",
      "Epoch: 002/010 | Batch 450/938 | Loss: 2.2411\n",
      "Epoch: 002/010 | Batch 500/938 | Loss: 2.2649\n",
      "Epoch: 002/010 | Batch 550/938 | Loss: 2.2638\n",
      "Epoch: 002/010 | Batch 600/938 | Loss: 2.2366\n",
      "Epoch: 002/010 | Batch 650/938 | Loss: 2.2310\n",
      "Epoch: 002/010 | Batch 700/938 | Loss: 2.2573\n",
      "Epoch: 002/010 | Batch 750/938 | Loss: 2.2376\n",
      "Epoch: 002/010 | Batch 800/938 | Loss: 2.2418\n",
      "Epoch: 002/010 | Batch 850/938 | Loss: 2.2387\n",
      "Epoch: 002/010 | Batch 900/938 | Loss: 2.2234\n",
      "Epoch: 002/010 training accuracy: 36.29%\n",
      "Time elapsed: 0.69 min\n",
      "Epoch: 003/010 | Batch 000/938 | Loss: 2.2222\n",
      "Epoch: 003/010 | Batch 050/938 | Loss: 2.2288\n",
      "Epoch: 003/010 | Batch 100/938 | Loss: 2.2193\n",
      "Epoch: 003/010 | Batch 150/938 | Loss: 2.2303\n",
      "Epoch: 003/010 | Batch 200/938 | Loss: 2.2394\n",
      "Epoch: 003/010 | Batch 250/938 | Loss: 2.2391\n",
      "Epoch: 003/010 | Batch 300/938 | Loss: 2.1819\n",
      "Epoch: 003/010 | Batch 350/938 | Loss: 2.1937\n",
      "Epoch: 003/010 | Batch 400/938 | Loss: 2.2079\n",
      "Epoch: 003/010 | Batch 450/938 | Loss: 2.1744\n",
      "Epoch: 003/010 | Batch 500/938 | Loss: 2.2129\n",
      "Epoch: 003/010 | Batch 550/938 | Loss: 2.2179\n",
      "Epoch: 003/010 | Batch 600/938 | Loss: 2.1707\n",
      "Epoch: 003/010 | Batch 650/938 | Loss: 2.1537\n",
      "Epoch: 003/010 | Batch 700/938 | Loss: 2.1996\n",
      "Epoch: 003/010 | Batch 750/938 | Loss: 2.1661\n",
      "Epoch: 003/010 | Batch 800/938 | Loss: 2.1690\n",
      "Epoch: 003/010 | Batch 850/938 | Loss: 2.1600\n",
      "Epoch: 003/010 | Batch 900/938 | Loss: 2.1447\n",
      "Epoch: 003/010 training accuracy: 54.01%\n",
      "Time elapsed: 1.07 min\n",
      "Epoch: 004/010 | Batch 000/938 | Loss: 2.1436\n",
      "Epoch: 004/010 | Batch 050/938 | Loss: 2.1390\n",
      "Epoch: 004/010 | Batch 100/938 | Loss: 2.1310\n",
      "Epoch: 004/010 | Batch 150/938 | Loss: 2.1572\n",
      "Epoch: 004/010 | Batch 200/938 | Loss: 2.1647\n",
      "Epoch: 004/010 | Batch 250/938 | Loss: 2.1738\n",
      "Epoch: 004/010 | Batch 300/938 | Loss: 2.0700\n",
      "Epoch: 004/010 | Batch 350/938 | Loss: 2.0909\n",
      "Epoch: 004/010 | Batch 400/938 | Loss: 2.1122\n",
      "Epoch: 004/010 | Batch 450/938 | Loss: 2.0563\n",
      "Epoch: 004/010 | Batch 500/938 | Loss: 2.1172\n",
      "Epoch: 004/010 | Batch 550/938 | Loss: 2.1322\n",
      "Epoch: 004/010 | Batch 600/938 | Loss: 2.0511\n",
      "Epoch: 004/010 | Batch 650/938 | Loss: 2.0187\n",
      "Epoch: 004/010 | Batch 700/938 | Loss: 2.0958\n",
      "Epoch: 004/010 | Batch 750/938 | Loss: 2.0371\n",
      "Epoch: 004/010 | Batch 800/938 | Loss: 2.0376\n",
      "Epoch: 004/010 | Batch 850/938 | Loss: 2.0192\n",
      "Epoch: 004/010 | Batch 900/938 | Loss: 2.0048\n",
      "Epoch: 004/010 training accuracy: 61.65%\n",
      "Time elapsed: 1.45 min\n",
      "Epoch: 005/010 | Batch 000/938 | Loss: 2.0060\n",
      "Epoch: 005/010 | Batch 050/938 | Loss: 1.9801\n",
      "Epoch: 005/010 | Batch 100/938 | Loss: 1.9740\n",
      "Epoch: 005/010 | Batch 150/938 | Loss: 2.0232\n",
      "Epoch: 005/010 | Batch 200/938 | Loss: 2.0263\n",
      "Epoch: 005/010 | Batch 250/938 | Loss: 2.0509\n",
      "Epoch: 005/010 | Batch 300/938 | Loss: 1.8804\n",
      "Epoch: 005/010 | Batch 350/938 | Loss: 1.9119\n",
      "Epoch: 005/010 | Batch 400/938 | Loss: 1.9377\n",
      "Epoch: 005/010 | Batch 450/938 | Loss: 1.8516\n",
      "Epoch: 005/010 | Batch 500/938 | Loss: 1.9405\n",
      "Epoch: 005/010 | Batch 550/938 | Loss: 1.9716\n",
      "Epoch: 005/010 | Batch 600/938 | Loss: 1.8442\n",
      "Epoch: 005/010 | Batch 650/938 | Loss: 1.7966\n",
      "Epoch: 005/010 | Batch 700/938 | Loss: 1.9165\n",
      "Epoch: 005/010 | Batch 750/938 | Loss: 1.8166\n",
      "Epoch: 005/010 | Batch 800/938 | Loss: 1.8162\n",
      "Epoch: 005/010 | Batch 850/938 | Loss: 1.7843\n",
      "Epoch: 005/010 | Batch 900/938 | Loss: 1.7744\n",
      "Epoch: 005/010 training accuracy: 66.78%\n",
      "Time elapsed: 1.83 min\n",
      "Epoch: 006/010 | Batch 000/938 | Loss: 1.7820\n",
      "Epoch: 006/010 | Batch 050/938 | Loss: 1.7268\n",
      "Epoch: 006/010 | Batch 100/938 | Loss: 1.7180\n",
      "Epoch: 006/010 | Batch 150/938 | Loss: 1.7847\n",
      "Epoch: 006/010 | Batch 200/938 | Loss: 1.7911\n",
      "Epoch: 006/010 | Batch 250/938 | Loss: 1.8471\n",
      "Epoch: 006/010 | Batch 300/938 | Loss: 1.6036\n",
      "Epoch: 006/010 | Batch 350/938 | Loss: 1.6455\n",
      "Epoch: 006/010 | Batch 400/938 | Loss: 1.6588\n",
      "Epoch: 006/010 | Batch 450/938 | Loss: 1.5508\n",
      "Epoch: 006/010 | Batch 500/938 | Loss: 1.6593\n",
      "Epoch: 006/010 | Batch 550/938 | Loss: 1.7104\n",
      "Epoch: 006/010 | Batch 600/938 | Loss: 1.5456\n",
      "Epoch: 006/010 | Batch 650/938 | Loss: 1.4978\n",
      "Epoch: 006/010 | Batch 700/938 | Loss: 1.6583\n",
      "Epoch: 006/010 | Batch 750/938 | Loss: 1.5025\n",
      "Epoch: 006/010 | Batch 800/938 | Loss: 1.5168\n",
      "Epoch: 006/010 | Batch 850/938 | Loss: 1.4699\n",
      "Epoch: 006/010 | Batch 900/938 | Loss: 1.4753\n",
      "Epoch: 006/010 training accuracy: 71.39%\n",
      "Time elapsed: 2.21 min\n",
      "Epoch: 007/010 | Batch 000/938 | Loss: 1.4939\n",
      "Epoch: 007/010 | Batch 050/938 | Loss: 1.4185\n",
      "Epoch: 007/010 | Batch 100/938 | Loss: 1.3927\n",
      "Epoch: 007/010 | Batch 150/938 | Loss: 1.4574\n",
      "Epoch: 007/010 | Batch 200/938 | Loss: 1.4843\n",
      "Epoch: 007/010 | Batch 250/938 | Loss: 1.5975\n",
      "Epoch: 007/010 | Batch 300/938 | Loss: 1.2994\n",
      "Epoch: 007/010 | Batch 350/938 | Loss: 1.3434\n",
      "Epoch: 007/010 | Batch 400/938 | Loss: 1.3351\n",
      "Epoch: 007/010 | Batch 450/938 | Loss: 1.2252\n",
      "Epoch: 007/010 | Batch 500/938 | Loss: 1.3345\n",
      "Epoch: 007/010 | Batch 550/938 | Loss: 1.3970\n",
      "Epoch: 007/010 | Batch 600/938 | Loss: 1.2293\n",
      "Epoch: 007/010 | Batch 650/938 | Loss: 1.1976\n",
      "Epoch: 007/010 | Batch 700/938 | Loss: 1.3738\n",
      "Epoch: 007/010 | Batch 750/938 | Loss: 1.1781\n",
      "Epoch: 007/010 | Batch 800/938 | Loss: 1.2298\n",
      "Epoch: 007/010 | Batch 850/938 | Loss: 1.1608\n",
      "Epoch: 007/010 | Batch 900/938 | Loss: 1.1943\n",
      "Epoch: 007/010 training accuracy: 75.33%\n",
      "Time elapsed: 2.58 min\n",
      "Epoch: 008/010 | Batch 000/938 | Loss: 1.2297\n",
      "Epoch: 008/010 | Batch 050/938 | Loss: 1.1463\n",
      "Epoch: 008/010 | Batch 100/938 | Loss: 1.0995\n",
      "Epoch: 008/010 | Batch 150/938 | Loss: 1.1558\n",
      "Epoch: 008/010 | Batch 200/938 | Loss: 1.1945\n",
      "Epoch: 008/010 | Batch 250/938 | Loss: 1.3720\n",
      "Epoch: 008/010 | Batch 300/938 | Loss: 1.0497\n",
      "Epoch: 008/010 | Batch 350/938 | Loss: 1.0870\n",
      "Epoch: 008/010 | Batch 400/938 | Loss: 1.0684\n",
      "Epoch: 008/010 | Batch 450/938 | Loss: 0.9668\n",
      "Epoch: 008/010 | Batch 500/938 | Loss: 1.0664\n",
      "Epoch: 008/010 | Batch 550/938 | Loss: 1.1239\n",
      "Epoch: 008/010 | Batch 600/938 | Loss: 0.9788\n",
      "Epoch: 008/010 | Batch 650/938 | Loss: 0.9629\n",
      "Epoch: 008/010 | Batch 700/938 | Loss: 1.1322\n",
      "Epoch: 008/010 | Batch 750/938 | Loss: 0.9268\n",
      "Epoch: 008/010 | Batch 800/938 | Loss: 1.0181\n",
      "Epoch: 008/010 | Batch 850/938 | Loss: 0.9249\n",
      "Epoch: 008/010 | Batch 900/938 | Loss: 0.9860\n",
      "Epoch: 008/010 training accuracy: 78.39%\n",
      "Time elapsed: 2.99 min\n",
      "Epoch: 009/010 | Batch 000/938 | Loss: 1.0387\n",
      "Epoch: 009/010 | Batch 050/938 | Loss: 0.9500\n",
      "Epoch: 009/010 | Batch 100/938 | Loss: 0.8913\n",
      "Epoch: 009/010 | Batch 150/938 | Loss: 0.9426\n",
      "Epoch: 009/010 | Batch 200/938 | Loss: 0.9746\n",
      "Epoch: 009/010 | Batch 250/938 | Loss: 1.2024\n",
      "Epoch: 009/010 | Batch 300/938 | Loss: 0.8776\n",
      "Epoch: 009/010 | Batch 350/938 | Loss: 0.8974\n",
      "Epoch: 009/010 | Batch 400/938 | Loss: 0.8854\n",
      "Epoch: 009/010 | Batch 450/938 | Loss: 0.7887\n",
      "Epoch: 009/010 | Batch 500/938 | Loss: 0.8809\n",
      "Epoch: 009/010 | Batch 550/938 | Loss: 0.9271\n",
      "Epoch: 009/010 | Batch 600/938 | Loss: 0.8033\n",
      "Epoch: 009/010 | Batch 650/938 | Loss: 0.7976\n",
      "Epoch: 009/010 | Batch 700/938 | Loss: 0.9564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009/010 | Batch 750/938 | Loss: 0.7544\n",
      "Epoch: 009/010 | Batch 800/938 | Loss: 0.8765\n",
      "Epoch: 009/010 | Batch 850/938 | Loss: 0.7640\n",
      "Epoch: 009/010 | Batch 900/938 | Loss: 0.8478\n",
      "Epoch: 009/010 training accuracy: 80.55%\n",
      "Time elapsed: 3.39 min\n",
      "Epoch: 010/010 | Batch 000/938 | Loss: 0.9076\n",
      "Epoch: 010/010 | Batch 050/938 | Loss: 0.8177\n",
      "Epoch: 010/010 | Batch 100/938 | Loss: 0.7523\n",
      "Epoch: 010/010 | Batch 150/938 | Loss: 0.8015\n",
      "Epoch: 010/010 | Batch 200/938 | Loss: 0.8219\n",
      "Epoch: 010/010 | Batch 250/938 | Loss: 1.0824\n",
      "Epoch: 010/010 | Batch 300/938 | Loss: 0.7637\n",
      "Epoch: 010/010 | Batch 350/938 | Loss: 0.7584\n",
      "Epoch: 010/010 | Batch 400/938 | Loss: 0.7629\n",
      "Epoch: 010/010 | Batch 450/938 | Loss: 0.6671\n",
      "Epoch: 010/010 | Batch 500/938 | Loss: 0.7568\n",
      "Epoch: 010/010 | Batch 550/938 | Loss: 0.7924\n",
      "Epoch: 010/010 | Batch 600/938 | Loss: 0.6806\n",
      "Epoch: 010/010 | Batch 650/938 | Loss: 0.6820\n",
      "Epoch: 010/010 | Batch 700/938 | Loss: 0.8337\n",
      "Epoch: 010/010 | Batch 750/938 | Loss: 0.6358\n",
      "Epoch: 010/010 | Batch 800/938 | Loss: 0.7797\n",
      "Epoch: 010/010 | Batch 850/938 | Loss: 0.6535\n",
      "Epoch: 010/010 | Batch 900/938 | Loss: 0.7566\n",
      "Epoch: 010/010 training accuracy: 82.27%\n",
      "Time elapsed: 3.79 min\n",
      "Total Training Time: 3.79 min \n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "total_step = len(train_loader)\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs, probas = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Logging\n",
    "        if not i % 50:\n",
    "            print('Epoch: %03d/%03d | Batch %03d/%03d | Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i, total_step, loss))\n",
    "    with torch.set_grad_enabled(False):\n",
    "        print('Epoch: %03d/%03d training accuracy: %.2f%%' %(\n",
    "        epoch+1, num_epochs, compute_accuracy(model, train_loader)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time) / 60))\n",
    "print('Total Training Time: %.2f min ' % ((time.time() - start_time) / 60))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
