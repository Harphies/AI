{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **Logistic Regression:**\n",
    "        \n",
    "-  logistic regression prediction are discrete (only specific value or categories are allowed). we can also view the probability scores underlying the model's classfication\n",
    "\n",
    "    **Types of Logistic Regression:**\n",
    "    - Binary (Yes/No)\n",
    "    - Multi class (orange, pineaple, mango, etc)\n",
    "    - Ordial (Low, Medium, High)\n",
    "\n",
    "    **Project:** An MNIST handwritten digit  classifier with Logistic Regression using pytorch \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages selection\n",
    "- The first things is to import all the neccesary packages needed for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings\n",
    "- define all the hyperparameters to be used and needs to be tuned to achive a better accuracy\n",
    "- Load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### Settings ###\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 784 # our image are 28 by 28 pixel in size \n",
    "# so each pixel requires a node unit so we have all together 784 node units in the input layer\n",
    "num_classes = 10 # output to predict is from(0,9)\n",
    "num_epochs = 5 # Number of training iterations (number of complte pass over the entire train data)\n",
    "batch_size = 100 # mini_batch size to speed up learning\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Dataset\n",
    "\n",
    "transfm = transforms.ToTensor() # transfrom the dataset object to tensors\n",
    "\n",
    "# MNIST dataset - images and labels\n",
    "train_data = datasets.MNIST(root='data',\n",
    "                           train=True,\n",
    "                           transform=transfm,\n",
    "                           download=True)\n",
    "\n",
    "test_data = datasets.MNIST(root='data',\n",
    "                          train=False,\n",
    "                          transform=transfm)\n",
    "\n",
    "# input pipeline\n",
    "train_loader = DataLoader(dataset=train_data,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the arcitecture of the model such as \n",
    "\n",
    "- The number of input layers; which is determined by the features of the data \n",
    "- Number of total hidden layers in the model (iterative)\n",
    "- Number of hidden units in each layers (iterative)\n",
    "- The output layer node units is determined by the intended outcome to achive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        predict = self.linear(x) # make a predictions with forward propagation\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function and optimizer\n",
    "- define the specific Loss function to use either cross entropy, MSELoss, etc\n",
    "- define the oprtization algorithm to use either SGD, Adam, RMSprop, Momentum etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "model = LogisticRegression(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss() # criterion is the same as loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) #The optimization algorithm of choice here is SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training  a model requires the following steps\n",
    " - Reset all the gradients to zero (0)\n",
    " - Make a forward pass (make a prediction)\n",
    " - Calculate the loss\n",
    " - Perform back propagation\n",
    " - Update all the parameters (weight and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss :2.1121270656585693\n",
      "Epoch 1, loss :2.003312110900879\n",
      "Epoch 1, loss :1.9126746654510498\n",
      "Epoch 1, loss :1.8258497714996338\n",
      "Epoch 1, loss :1.7991440296173096\n",
      "Epoch 1, loss :1.7355778217315674\n",
      "Epoch 2, loss :1.649955153465271\n",
      "Epoch 2, loss :1.5857528448104858\n",
      "Epoch 2, loss :1.5291244983673096\n",
      "Epoch 2, loss :1.4944807291030884\n",
      "Epoch 2, loss :1.4568406343460083\n",
      "Epoch 2, loss :1.4333828687667847\n",
      "Epoch 3, loss :1.4340980052947998\n",
      "Epoch 3, loss :1.4033045768737793\n",
      "Epoch 3, loss :1.3247932195663452\n",
      "Epoch 3, loss :1.2865005731582642\n",
      "Epoch 3, loss :1.257014513015747\n",
      "Epoch 3, loss :1.3432790040969849\n",
      "Epoch 4, loss :1.1527975797653198\n",
      "Epoch 4, loss :1.0792630910873413\n",
      "Epoch 4, loss :1.1181960105895996\n",
      "Epoch 4, loss :1.2132201194763184\n",
      "Epoch 4, loss :1.0781160593032837\n",
      "Epoch 4, loss :1.1612967252731323\n",
      "Epoch 5, loss :1.0190832614898682\n",
      "Epoch 5, loss :0.9546176791191101\n",
      "Epoch 5, loss :1.009333848953247\n",
      "Epoch 5, loss :1.025702714920044\n",
      "Epoch 5, loss :0.9217512607574463\n",
      "Epoch 5, loss :0.8922644853591919\n"
     ]
    }
   ],
   "source": [
    "## Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28 * 28)) # Image flanned into 1D tensor (column vector)\n",
    "        labels = Variable(labels) # label\n",
    "        \n",
    "        # Forward -> Backprop -> optimize\n",
    "        optimizer.zero_grad() # manually zero the gradient buffers\n",
    "        output = model(images) # make a predition on the test set\n",
    "        loss = criterion(output,labels) # compute the loss given the predicted label\n",
    "                                        # and the actual label\n",
    "        \n",
    "        loss.backward() # compute the error gradients with back propagation\n",
    "        optimizer.step() # optimize the model via stochastic gradient descent\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\"Epoch {}, loss :{}\".format(epoch + 1, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy: 83\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print(\"Acurracy: {}\".format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
