{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-model-as-restAPI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji5vM-n59xLc",
        "outputId": "4194c5ca-fd21-4b8a-dc15-e87326d66b12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/kamalkraj/BERT-SQuAD\n",
        "!pip install -q -r \"BERT-SQuAD/requirements.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BERT-SQuAD'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 26 (delta 4), reused 16 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (26/26), done.\n",
            "\u001b[K     |████████████████████████████████| 143kB 4.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 5.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 13.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 14.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.7MB 23.5MB/s \n",
            "\u001b[31mERROR: botocore 1.19.8 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhrYIa_J94m1"
      },
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import sys \n",
        "sys.path.append(\"BERT-SQuAD\")\n",
        "from bert import QA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSL2itEk-C9U",
        "outputId": "d14bf790-93ec-4dfe-cb8f-fcab0d4956fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "app = Flask(__name__)\n",
        "# CORS(app)\n",
        "\n",
        "model = QA(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
        "\n",
        "@app.route(\"/predict\", methods=['POST'])\n",
        "def predict():\n",
        "    paragraph = request.json['paragraph']\n",
        "    question = request.json['question']\n",
        "    try:\n",
        "        out = model.predict(paragraph, question)\n",
        "        return jsonify({\"result\": out})\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return jsonify({\"result\": \"Model failed\"})\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run('0.0.0.0',port=8000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model name 'bert-large-uncased-whole-word-masking-finetuned-squad/bert_config.json' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). We assumed 'bert-large-uncased-whole-word-masking-finetuned-squad/bert_config.json' was a path or url but couldn't find any file associated to this path or url.\n",
            "The pre-trained model you are loading is an uncased model but you have set `do_lower_case` to False. We are setting `do_lower_case=True` for you but you may want to check this behavior.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://0.0.0.0:8000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4ZKfiX8-qYy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}